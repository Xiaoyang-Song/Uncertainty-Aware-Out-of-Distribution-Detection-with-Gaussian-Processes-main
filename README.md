# **Uncertainty-Aware Out-of-Distribution Detection with Gaussian Processes**


## Description

This repository contains the official implementation of the paper:  
**"Uncertainty-Aware Out-of-Distribution Detection with Gaussian Processes"**

Deep neural networks (DNNs) often fail to handle out-of-distribution (OOD) data, leading to overconfident and incorrect predictions, especially in safety-critical tasks. Existing OOD detection methods typically rely on curated OOD data or hyperparameter tuning, limiting their effectiveness without exposure to OOD samples during training.

To address this, we propose a Gaussian-process-based OOD detection method that establishes a detection boundary using only in-distribution (InD) data. By quantifying uncertainty in softmax scores with a clustered Gaussian process, our approach defines a score function to separate InD and OOD data based on differences in their posterior predictive distributions. The proposed method consistently outperforms state-of-the-art techniques in detection accuracy while requiring no OOD data during training.

In this repository, we provide the pre-trained neural network checkpoints and ready-to-run R code for reproducing our proposed Gaussian Process-based OOD detection results. This version is tailored more towards statisticians. In addition, we also include detailed information on the neural network training procedures and the corresponding source code, for those who wish to train the model from scratch for their own research.

---

## Gaussian Process-Based OOD Detection

Gaussian process training utilizes feature representations
 obtained from pre-trained neural network classification models. Specifically, the feature representations generated by pre-trained neural networks are used for fitting Gaussian process models. The pre-trained checkpoints and extracted feature representations for InD and OOD data are provided under the folder `./GP-Fitting/data`. These datasets have a feature dimension of 32, allowing you to start GP fitting immediately if desired.


Alternatively, if you want to utilize your own checkpoints later, you can either move all relevant `.csv` data files to `./GP-Fitting/data` or modify the directory paths directly in `laGP_ImageNet.R` or `laGP_MNIST.R` to point to the correct data locations.

<!-- We recommend moving all relevant `.csv` data files from `./NN-Training/ckpt` to `./GP-Fitting/data` for training the GP model.  -->

<!-- Alternatively, you can modify the directory paths directly in `laGP_ImageNet.R` or `laGP_MNIST.R` to point to the correct data locations. -->

<!-- For your convenience, we have provided example datasets for both MNIST and ImageNet in the `./GP-Fitting/data` directory. These datasets have a feature dimension of 32, allowing you to start GP fitting immediately if desired. -->

Now, we provide instructions on reproducing our results from provided pre-trained neural network model checkpoints. First, move to the source directory of Gaussian process fitting.
```
cd GP-Fitting
```

Ensure R is installed on your system. Refer to the [R installation guide](https://cran.r-project.org/) for instructions. Then run the following command to install all required R packages:
```
Rscript install_packages.R
```

#### MNIST experiment
After installing all dependencies, you can execute the main script for MNIST by running:  
```bash
Rscript laGP_MNIST.R
```
Once executed, the outputs will be saved in `./GP-Fitting/results_mnist.txt`. Additionally, the R data from model fitting will be stored in `./GP-Fitting/Rdata_ckpt`.

You can easily customize various parameters in `laGP_MNIST.R`, such as sample sizes, feature dimensions, and more, to suit your specific needs.



#### ImageNet experiment
To fit a Gaussian Process (GP) model on ImageNet data, run the following command in your terminal:

```bash
Rscript laGP_ImageNet.R
```

The outputs and checkpoint Rdata files will be stored in locations similar to those used for MNIST experiments.
<!-- For ImageNet, a key difference is that you can evaluate multiple groups of data. These datasets follow the naming format `imagenet10-32-0-o1`. To test a specific group of data trained from the neural network, simply update the dataset name in the code. More details can be found in the next section. -->

## Neural Network Pre-Training
Here we also provide the complete instructions for training neural network classification models from scratch. The checkpoints of the results below are already introduced before and are provided in this repository.

### Dataset Download
Here we provide the following instructions for downloading relevant InD and OOD datasets used in this paper.

#### In-Distribution Dataset

The ImageNet10 dataset that we used is a subset of the well-known ImageNet1k (ILSVRC-2012) dataset. An automation `.sh` script for downloading this can be found [here](https://gist.github.com/BIGBALLON/8a71d225eff18d88e469e6ea9b39cef4). Alternatively, if you experience unexpected issues with using this automation script, we recommend manually download the dataset from [this website](https://www.image-net.org/index.php). The downloaded training and validation dataset should be extracted and placed in `./NN-Training/data/train` and `./NN-Training/data/val`, respectively. Typically, this download process will take a few hours even with automation script.

The 10 sub-classes in our ImageNet10 dataset are pre-chosen and are hard-coded in our codebase, which inherits from the codebase developed by [Ming et. al (2022)](https://github.com/deeplearning-wisc/MCM/tree/main?tab=readme-ov-file). 

For simple benchmarking MNIST dataset, it can be easily retrieved from Pytorch dataset library.

#### Out-of-Distribution Dataset

For downloading OOD datasets, we kindly refer the audience to the instructions mentioned in the "Dataset Preparation" section of [this repository](https://github.com/deeplearning-wisc/cider). For instance, to download LSUN-C dataset, you can run:
```
cd NN-Training/data
wget https://www.dropbox.com/s/fhtsw1m3qxlwj6h/LSUN.tar.gz
tar -xvzf LSUN.tar.gz
```

However, please keep in mind that all downloaded and extracted data should be placed under the folder `./NN-Training/data/`. 

For simple OOD datasets used in MNIST benchmarking experiment, including CIFAR10, FashionMNIST, and [mini-ImageNet](https://drive.google.com/file/d/1Kot50VljGnN4exQtxN76_PoJhPrFJTim/view?usp=sharing), they can be either retrieved from the provided link or Pytorch dataset library.

### Environment Specification
Some key OS and environment specifications that this code is developed on are provided as follow. 
```
Red Hat Enterprise Linux (RHEL) 8.10
python=3.9.7
pytorch=1.12.1
CUDA=12.8.0
CUDA Driver Version=570.124.06
```
For your ease, we provide the following setup command:
```
conda env create -f environment.yml
```
However, if in case this command does not work as expected due to conflicts with OS or your local environment, we recommend download missing packages from `pip` or `conda` one after another, depending on the package management system used in your local devices. There are no specific version requirements as long as they are compatiable with the above versions.
For OS, we recommend running this on a RHEL system, which is common for cloud server. However, a windows OS with version 10+ with the specified cuda driver should also work smoothly. For hardware, this code is primarily developed on Tesla V100-PCIE-16GB and NVIDIA A100 16GB. That said, any properly configured GPU with at least 12 GB memory should work smoothly.

### Neural Network Training

<!-- (This step can be skipped by using our pre-generated data in `./GP-Fitting/data` for GP fitting, which saves time. However, you are welcome to generate data with different settings if needed.)

 -->
First, from the main directory, 
```
cd NN-Training
```
#### MNIST experiment

For MNIST experiment, as the classification task is not very difficult, we choose to hardcode all parameters in the script; the command is given by:

```
python mnist.py
```

However, those parameters, including learning rate, feature size, batch size, and epochs, can be adjusted easily in `mnist.py`.

#### ImageNet experiment

To train a classifier for ImageNet10 dataset and evaluate them on all OOD datasets, one example command is provided as follows:

```
python imagenet.py --lr=0.1 --num_classes=10 --bsz=256 --n_features=32 --dset_id 0 --train --eval_train
```

Note that the learning rate, batch size, and the number of features in the penultimate layer can be adjusted from the command. To evaluate on the OOD datasets, we can simply specify the dataset by adding `--ood <dset name>` and remove the `--train` and `--eval_train` flag to avoid repetitve training. For instance, one example command is provided as follows:

```
python imagenet.py --lr=0.1 --num_classes=10 --bsz=256 --n_features=32 --dset_id 0 --ood Places365
```

After training and evaluation, the trained model checkpoint as well as all features are saved under the folder `ckpt/`. These features and logits will then be utilized for training of GP models.

## Contributions
We extend our gratitude to the contributors who provided valuable insights and resources that facilitated the development of this project.

## Citing
The paper is under review.